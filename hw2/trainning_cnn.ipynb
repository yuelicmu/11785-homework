{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_fea.npy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-308372833eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#train_label = np.load('../dataset/train_labels.npy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#testX = np.load('../dataset/test_feats.npy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_fea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_fea.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest_fea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_fea.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_fea.npy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hw2 import preprocessing as P\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from hw2 import all_cnn as A\n",
    "\n",
    "trainX = np.load('../dataset/train_feats.npy')\n",
    "train_label = np.load('../dataset/train_labels.npy')\n",
    "testX = np.load('../dataset/test_feats.npy')\n",
    "train_fea = np.load('train_fea.npy')\n",
    "test_fea = np.load('test_fea.npy')\n",
    "\n",
    "print('Begin initialization.')\n",
    "\n",
    "\n",
    "def to_tensor(numpy_array):\n",
    "    # Numpy array -> Tensor\n",
    "    return torch.from_numpy(numpy_array).float()\n",
    "\n",
    "\n",
    "def to_variable(tensor):\n",
    "    # Tensor -> Variable (on GPU if possible)\n",
    "    if torch.cuda.is_available():\n",
    "        # Tensor -> GPU Tensor\n",
    "        tensor = tensor.cuda()\n",
    "    return torch.autograd.Variable(tensor)\n",
    "\n",
    "\n",
    "trainY_tensor = to_tensor(train_label)\n",
    "trainY_tensor = trainY_tensor.type('torch.LongTensor')\n",
    "\n",
    "\n",
    "class TestDataSet(torch.utils.data.TensorDataset):\n",
    "    def __init__(self, data_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.shape(self.data_tensor)[0]\n",
    "\n",
    "\n",
    "print('Finish initialization.')\n",
    "\n",
    "LEARN_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "def training_routine(data, labels_binary, num_epochs, minibatch_size, learn_rate):\n",
    "    my_net = A.all_cnn_module()  # Create the network,\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()  # and choose the loss function / optimizer\n",
    "    optim = torch.optim.SGD(my_net.parameters(), lr=learn_rate, momentum=0.9)\n",
    "    dataset = torch.utils.data.TensorDataset(to_tensor(data), labels_binary)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=minibatch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        i = 0\n",
    "        for (input_val, label) in data_loader:\n",
    "            optim.zero_grad()  # Reset the gradients\n",
    "            prediction = my_net(to_variable(input_val))  # Feed forward # [torch.FloatTensor of size 11x10]\n",
    "            loss = loss_fn(prediction, to_variable(label))  # Compute losses\n",
    "            loss.backward()  # Backpropagate the gradients\n",
    "            losses.append(loss.data.cpu().numpy())\n",
    "            optim.step()  # Update the network\n",
    "            #if i % 100 == 0:\n",
    "            #    print(i//100, end=', ')\n",
    "            #i += 1\n",
    "            print(i, end=',')\n",
    "            i += 1\n",
    "        print(\"Epoch {} Loss: {:.4f}\".format(epoch, np.asscalar(np.mean(losses))))\n",
    "    return my_net\n",
    "\n",
    "\n",
    "trained_net = training_routine(train_fea, trainY_tensor, 2, 11, 0.001)\n",
    "test_data = TestDataSet(to_tensor(train_fea))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=1, shuffle=False)\n",
    "test_data_real = TestDataSet(to_tensor(test_fea))\n",
    "test_real_loader = torch.utils.data.DataLoader(\n",
    "    test_data_real, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "def classification(net, loader):\n",
    "    label_lst = []\n",
    "    for input_val in loader:\n",
    "        input = to_variable(input_val)\n",
    "        y = net(input)\n",
    "        label = np.argsort(y.data.cpu().numpy())[0][-1]\n",
    "        label_lst.append(label)\n",
    "    return label_lst\n",
    "\n",
    "\n",
    "def accuracy(label_lst, truth):\n",
    "    n = len(label_lst)\n",
    "    acc = 0\n",
    "    for i in range(n):\n",
    "        if label_lst[i] == int(truth[i]):\n",
    "            acc += 1\n",
    "    return acc, acc / n\n",
    "\n",
    "\n",
    "\n",
    "print('Finish initialization.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARN_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "def training_routine(data, labels_binary, num_epochs, minibatch_size, learn_rate):\n",
    "    my_net = A.all_cnn_module()  # Create the network,\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()  # and choose the loss function / optimizer\n",
    "    optim = torch.optim.SGD(my_net.parameters(), lr=learn_rate, momentum=0.9)\n",
    "    dataset = torch.utils.data.TensorDataset(to_tensor(data), labels_binary)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=minibatch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        for (input_val, label) in data_loader:\n",
    "            optim.zero_grad()  # Reset the gradients\n",
    "            prediction = my_net(to_variable(input_val))  # Feed forward # [torch.FloatTensor of size 11x10]\n",
    "            loss = loss_fn(prediction, to_variable(label))  # Compute losses\n",
    "            loss.backward()  # Backpropagate the gradients\n",
    "            losses.append(loss.data.cpu().numpy())\n",
    "            optim.step()  # Update the network\n",
    "        print(\"Epoch {} Loss: {:.4f}\".format(epoch, np.asscalar(np.mean(losses))))\n",
    "    return my_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_net = training_routine(train_fea, trainY_tensor, 2, 11, 0.001)\n",
    "test_data = TestDataSet(to_tensor(train_fea))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=1, shuffle=False)\n",
    "test_data_real = TestDataSet(to_tensor(test_fea))\n",
    "test_real_loader = torch.utils.data.DataLoader(\n",
    "    test_data_real, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "def classification(net, loader):\n",
    "    label_lst = []\n",
    "    for input_val in loader:\n",
    "        input = to_variable(input_val)\n",
    "        y = net(input)\n",
    "        label = np.argsort(y.data.cpu().numpy())[0][-1]\n",
    "        label_lst.append(label)\n",
    "    return label_lst\n",
    "\n",
    "\n",
    "def accuracy(label_lst, truth):\n",
    "    n = len(label_lst)\n",
    "    acc = 0\n",
    "    for i in range(n):\n",
    "        if label_lst[i] == int(truth[i]):\n",
    "            acc += 1\n",
    "    return acc, acc / n\n",
    "\n",
    "\n",
    "trained_label = classification(trained_net, test_loader)\n",
    "acc = accuracy(trained_label, train_label)\n",
    "test_label = classification(trained_net, test_real_loader)\n",
    "np.save('test_label.npy', test_label)\n",
    "print(acc)\n",
    "for i in range(100):\n",
    "    print(trained_label[i], train_label[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
